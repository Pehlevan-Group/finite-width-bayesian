{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "conv1D_experiment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGyC5GpDPAoK"
      },
      "source": [
        "!pip install --upgrade --no-deps --force-reinstall -q git+https://github.com/Pehlevan-Group/finite-width-bayesian\n",
        "!pip install neural_tangents"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5gv6vy0O1ix"
      },
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import neural_tangents as nt\n",
        "from neural_tangents import stax\n",
        "\n",
        "from langevin import model\n",
        "from langevin.utils import convert_nt, curr_time\n",
        "import langevin.theory as theory\n",
        "import langevin.optimizer as opt\n",
        "import langevin.dataset as ds\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import random\n",
        "from jax import jit, grad, vmap\n",
        "from jax.config import config\n",
        "config.update(\"jax_enable_x64\", True)\n",
        "key = random.PRNGKey(1)\n",
        "\n",
        "from functools import partial\n",
        "from skimage.transform import resize\n",
        "\n",
        "import pytz\n",
        "from datetime import datetime\n",
        "from dateutil.relativedelta import relativedelta\n",
        "\n",
        "def time_diff(t_start):\n",
        "    t_end = datetime.now(pytz.timezone('US/Eastern'))\n",
        "    t_diff = relativedelta(t_end, t_start)  # later/end time comes first!\n",
        "    return '{h}h {m}m {s}s'.format(h=t_diff.hours, m=t_diff.minutes, s=t_diff.seconds)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAmYfZtnO1i1",
        "outputId": "7edc1713-39f2-4937-ce8d-c6ba60fa3c31"
      },
      "source": [
        "dataset_name = 'mnist'\n",
        "model_type = 'cnn1d'\n",
        "opt_mode = 'sgld'\n",
        "nonlin = 'linear'\n",
        "\n",
        "N_tr = 50\n",
        "resized = 5\n",
        "x_train, y_train = ds.dataset(N_tr, dataset_name, model_type, resized);\n",
        "print(x_train.shape)\n",
        "\n",
        "hidden_widths = [[250,250], [400,400], [500,500], [600,600], [700,700], [750,750]]\n",
        "beta = 1\n",
        "batch_size = N_tr\n",
        "step_size = 1/2000\n",
        "batch_factor = N_tr//batch_size\n",
        "\n",
        "nT = 2000\n",
        "burn_in = nT//4"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50, 25, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "fGoOJe72O1i3"
      },
      "source": [
        "K_avgs = []\n",
        "K_nngps = []\n",
        "Kernel_Fns = []\n",
        "## Compute the theory\n",
        "K_theories = []\n",
        "for hidden_width in hidden_widths:\n",
        "    print(model_type, ' | ', hidden_width)\n",
        "\n",
        "    ## Create the model layers\n",
        "    layers, layers_ker = model.model(hidden_width, nonlin = nonlin, model_type = model_type)\n",
        "    ## Create the model functions for each layer\n",
        "    init_fn, apply_fn, kernel_fn, layer_fns, kernel_fns, emp_kernel_fns = model.network_fns(layers, x_train)\n",
        "    ## Initialize the model\n",
        "    _, params = init_fn(key, input_shape=x_train.shape)\n",
        "\n",
        "    ## Set Optimizer\n",
        "    opt_init, opt_update, get_params = opt.sgld(step_size, beta, batch_factor)\n",
        "    opt_state = opt_init(params)\n",
        "    \n",
        "    ## Set Loss Function and its grad\n",
        "    loss_fn = jit(lambda params: jnp.sum((apply_fn(params,x_train)-y_train)**2)/2)\n",
        "    g_loss = jit(grad(loss_fn))\n",
        "\n",
        "    avg_count = 0\n",
        "    K_avg = []\n",
        "    t_start = curr_time()\n",
        "    for j in range(nT):\n",
        "        opt_params = get_params(opt_state)\n",
        "        opt_state = opt_update(j, g_loss(opt_params), opt_state)\n",
        "\n",
        "        if j > burn_in:\n",
        "            avg_count += 1\n",
        "            for i, idx in enumerate(layers_ker):\n",
        "                if j == burn_in + 1:\n",
        "                    K_avg += [emp_kernel_fns[idx](opt_params[:idx+1])]\n",
        "                else: \n",
        "                    K_avg[i] += emp_kernel_fns[idx](opt_params[:idx+1])\n",
        "\n",
        "        if j % 1000 == 0:\n",
        "            print('%d | loss: %f | avg_count: %d | time: %s'%(j, loss_fn(opt_params), avg_count, time_diff(t_start)), flush=True)\n",
        "    \n",
        "    K_nngp, K_theory, Gxx, Gyy = theory.theory_linear(x_train, y_train, beta, kernel_fns, hidden_width)\n",
        "    K_nngps += [K_nngp]\n",
        "    K_theories += [K_theory]\n",
        "\n",
        "        \n",
        "    with open('data_%s_%d_%s_%s_%s.pkl'%(str(hidden_width), N_tr, model_type, opt_mode, nonlin), 'wb') as outfile:\n",
        "        pickle.dump({'K_avg': K_avg, 'K_nngp': K_nngp, 'K_theory': K_theory, \n",
        "                 'model_type': model_type, 'hidden_widths': hidden_widths, 'N_tr': N_tr, \n",
        "                 'nT': nT, 'beta': beta, 'batch_size': batch_size, 'step_size': step_size,\n",
        "                 'avg_count': avg_count, 'opt_mode': opt_mode}, outfile, pickle.HIGHEST_PROTOCOL)\n",
        "                 \n",
        "\n",
        "    if model_type == 'fnn':\n",
        "        plt.scatter((K_avg[0]/avg_count-Gxx).reshape(-1)[:], (K_theory[0]-Gxx).reshape(-1)[:], label='Width: %d'%hidden_width[0])\n",
        "        plt.savefig('k-nngp_%s_fnn_%s_%s.jpg'%(str(hidden_width), opt_mode, nonlin))\n",
        "        plt.close()\n",
        "    \n",
        "        plt.scatter((K_avg[0]/avg_count).reshape(-1)[:], (K_theory[0]).reshape(-1)[:], label='Width: %d'%hidden_width[0])\n",
        "        plt.savefig('k_vs_nngp_%s_fnn_%s_%s.jpg'%(str(hidden_width), opt_mode, nonlin))\n",
        "        plt.close()\n",
        "\n",
        "        \n",
        "with open('data_%d_%s_%s_%s.pkl'%(N_tr, model_type, opt_mode, nonlin), 'wb') as outfile:\n",
        "    pickle.dump({'K_avgs': K_avgs, 'K_nngps': K_nngps, 'K_theories': K_theories, \n",
        "                 'model_type': model_type, 'hidden_widths': hidden_widths, 'N_tr': N_tr, \n",
        "                 'nT': nT, 'beta': beta, 'batch_size': batch_size, 'step_size': step_size,\n",
        "                 'avg_count': avg_count, 'opt_mode': opt_mode}, outfile, pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LqJVK4SZYYu"
      },
      "source": [
        "K_avgs = []\n",
        "K_nngps = []\n",
        "avg_counts = []\n",
        "nTs = []\n",
        "\n",
        "nonlin = 'linear'\n",
        "data_files = ['data_%s_50_cnn1d_sgld_%s.pkl'%(str(s),nonlin) for s in hidden_widths]\n",
        "\n",
        "for data_file in data_files:\n",
        "    with open(data_file, 'rb') as infile:\n",
        "        data = pickle.load(infile)\n",
        "        N_tr = data['N_tr']\n",
        "        model_type= data['model_type']\n",
        "        K_avgs += [data['K_avg']]\n",
        "        K_nngps += [data['K_nngp']]\n",
        "        avg_counts += [data['avg_count']]\n",
        "        nTs += [data['nT']]\n",
        "        beta = data['beta']\n",
        "\n",
        "## Preprocess NT kernels\n",
        "for i, K_width in zip(np.arange(len(K_avgs)), K_avgs):\n",
        "    for j, K in enumerate(K_width):\n",
        "        K_avgs[i][j] =  convert_nt(K)/avg_count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZu_sHxnO1i5"
      },
      "source": [
        "depths = jnp.arange(len(K_avgs[0]))\n",
        "widths = []\n",
        "deviation = []\n",
        "deviation_th = []\n",
        "\n",
        "for i, hidden_width in enumerate(hidden_widths):\n",
        "    widths += [hidden_width[0]]\n",
        "    K_exp = K_avgs[i]\n",
        "    K_nngp = K_nngps[i]\n",
        "    K_theory = K_theories[i]\n",
        "\n",
        "    deviation += [[jnp.linalg.norm(K - K_t)**2 for K, K_t in zip(K_exp, K_nngp)]]\n",
        "    deviation_th += [[jnp.linalg.norm(K - K_t)**2 for K, K_t in zip(K_theory, K_nngp)]]\n",
        "\n",
        "widths = np.array(widths)\n",
        "deviation = np.array(deviation)\n",
        "deviation_th = np.array(deviation_th)\n",
        "print(deviation.shape)\n",
        "plt.loglog(widths, deviation[:,:-2], 'o')\n",
        "plt.loglog(widths, deviation_th, '-')\n",
        "# plt.loglog(widths, 1/widths, '--')\n",
        "    \n",
        "plt.savefig('one_over_width_%s_%s_%s.png'%(model_type, opt_mode, nonlin))\n",
        "plt.show()\n",
        "\n",
        "fig, axs = plt.subplots(1,2)\n",
        "\n",
        "axs[0].imshow(K_avgs[0][-1]/avg_count)\n",
        "axs[1].imshow(K_nngps[0][-1])\n",
        "plt.show()\n",
        "\n",
        "K_exp = [K/avg_count for K in K_avg[:-2]]\n",
        "K_nngp_th = [K/avg_count for K in K_nngp[:-2]]\n",
        "\n",
        "fig, axs = plt.subplots(1,2)\n",
        "lay_idx = 1\n",
        "img_idx1 = 40\n",
        "img_idx2 = 40\n",
        "axs[0].imshow(K_exp[lay_idx][img_idx1,img_idx2]/avg_count)\n",
        "axs[1].imshow(K_exp[lay_idx][img_idx1,img_idx2]/avg_count - K_nngp_th[lay_idx][img_idx1,img_idx2])\n",
        "plt.savefig('K_cov_%s_%s_%s.jpg'%(model_type, opt_mode, nonlin))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tb651xQzYvi_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}