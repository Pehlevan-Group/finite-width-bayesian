{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "conv2D_experiment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNUilbF5d91n"
      },
      "source": [
        "!pip install --upgrade --no-deps --force-reinstall -q git+https://github.com/Pehlevan-Group/finite-width-bayesian\n",
        "!pip install neural_tangents"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgNAlhuwd-OB"
      },
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import neural_tangents as nt\n",
        "from neural_tangents import stax\n",
        "import langevin.optimizer as opt\n",
        "import langevin.theory as theory\n",
        "import langevin.model as model\n",
        "import langevin.dataset as ds\n",
        "from langevin.utils import convert_nt, curr_time\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import random\n",
        "from jax import jit, grad, vmap\n",
        "from jax.config import config\n",
        "config.update(\"jax_enable_x64\", True)\n",
        "key = random.PRNGKey(1)\n",
        "\n",
        "from functools import partial\n",
        "from skimage.transform import resize\n",
        "\n",
        "import pytz\n",
        "from datetime import datetime\n",
        "from dateutil.relativedelta import relativedelta\n",
        "\n",
        "def time_diff(t_start):\n",
        "    t_end = datetime.now(pytz.timezone('US/Eastern'))\n",
        "    t_diff = relativedelta(t_end, t_start)  # later/end time comes first!\n",
        "    return '{h}h {m}m {s}s'.format(h=t_diff.hours, m=t_diff.minutes, s=t_diff.seconds)\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fofWca3YeCLz"
      },
      "source": [
        "dataset_name = 'mnist'\n",
        "model_type = 'cnn'\n",
        "opt_mode = 'sgld'\n",
        "nonlin = 'linear'\n",
        "\n",
        "N_tr = 50\n",
        "resized = 10\n",
        "x_train, y_train = ds.dataset(N_tr, dataset_name, model_type, resized);\n",
        "    \n",
        "    \n",
        "hidden_widths = [[50,50],[100,100],[150,150],[200,200],[250,250],[300,300],[350,350],[400,400],[500,500],[600,600]]\n",
        "beta = 1\n",
        "batch_size = N_tr\n",
        "step_size = 1/1000\n",
        "batch_factor = N_tr//batch_size\n",
        "\n",
        "## Set this to 3000000 to obtain an accurate posterior mean\n",
        "nT = 3000000\n",
        "burn_in = nT//3\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jFiPKpIeoKd"
      },
      "source": [
        "K_avgs = []\n",
        "K_nngps = []\n",
        "\n",
        "## Compute the theory\n",
        "K_theories = []\n",
        "for hidden_width in hidden_widths:\n",
        "    print(model_type, ' | ', hidden_width)\n",
        "\n",
        "    ## Create the model layers\n",
        "    layers, layers_ker = model.model(hidden_width, nonlin = nonlin, model_type = model_type)\n",
        "    ## Create the model functions for each layer\n",
        "    init_fn, apply_fn, kernel_fn, layer_fns, kernel_fns, emp_kernel_fns = model.network_fns(layers, x_train)\n",
        "    ## Initialize the model\n",
        "    _, params = init_fn(key, input_shape=x_train.shape)\n",
        "\n",
        "    ## Set Optimizer\n",
        "    opt_init, opt_update, get_params = opt.sgld(step_size, beta, batch_factor)\n",
        "    opt_state = opt_init(params)\n",
        "    \n",
        "    ## Set Loss Function and its grad\n",
        "    loss_fn = jit(lambda params: jnp.sum((apply_fn(params,x_train)-y_train)**2)/2)\n",
        "    g_loss = jit(grad(loss_fn))\n",
        "\n",
        "    avg_count = 0\n",
        "    K_avg = []\n",
        "    t_start = curr_time()\n",
        "    for j in range(nT):\n",
        "        opt_params = get_params(opt_state)\n",
        "        opt_state = opt_update(j, g_loss(opt_params), opt_state)\n",
        "\n",
        "        if j > burn_in:\n",
        "            avg_count += 1\n",
        "            for i, idx in enumerate(layers_ker):\n",
        "                if j == burn_in + 1:\n",
        "                    K_avg += [emp_kernel_fns[idx](opt_params[:idx+1])]\n",
        "                else: \n",
        "                    K_avg[i] += emp_kernel_fns[idx](opt_params[:idx+1])\n",
        "\n",
        "        if j % 1000 == 0:\n",
        "            print('%d | loss: %f | avg_count: %d | time: %s'%(j, loss_fn(opt_params), avg_count, time_diff(t_start)), flush=True)\n",
        "    \n",
        "    K_nngp, K_theory, Gxx, Gyy = theory.theory_linear(x_train, y_train, beta, kernel_fns, hidden_width)\n",
        "    K_nngps += [K_nngp]\n",
        "    K_theories += [K_theory]\n",
        "\n",
        "    with open('data_%s_%d_%s_%s_%s.pkl'%(str(hidden_width), N_tr, model_type, opt_mode, nonlin), 'wb') as outfile:\n",
        "        pickle.dump({'K_avg': K_avg, 'K_nngp': K_nngp, 'K_theory': K_theory, \n",
        "                 'model_type': model_type, 'hidden_widths': hidden_widths, 'N_tr': N_tr, \n",
        "                 'nT': nT, 'beta': beta, 'batch_size': batch_size, 'step_size': step_size,\n",
        "                 'avg_count': avg_count, 'opt_mode': opt_mode}, outfile, pickle.HIGHEST_PROTOCOL) \n",
        "\n",
        "        \n",
        "with open('data_%d_%s_%s_%s.pkl'%(N_tr, model_type, opt_mode, nonlin), 'wb') as outfile:\n",
        "    pickle.dump({'K_avgs': K_avgs, 'K_nngps': K_nngps, 'K_theories': K_theories, \n",
        "                 'model_type': model_type, 'hidden_widths': hidden_widths, 'N_tr': N_tr, \n",
        "                 'nT': nT, 'beta': beta, 'batch_size': batch_size, 'step_size': step_size,\n",
        "                 'avg_count': avg_count, 'opt_mode': opt_mode}, outfile, pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CMhR67rfUj0"
      },
      "source": [
        "K_avgs = []\n",
        "K_nngps = []\n",
        "avg_counts = []\n",
        "nTs = []\n",
        "\n",
        "nonlin = 'linear'\n",
        "data_files = ['data_%s_%d_%s_%s_%s.pkl'%(str(s), N_tr, model_type, opt_mode, nonlin) for s in hidden_widths]\n",
        "\n",
        "for data_file in data_files:\n",
        "    with open(data_file, 'rb') as infile:\n",
        "        data = pickle.load(infile)\n",
        "        N_tr = data['N_tr']\n",
        "        model_type= data['model_type']\n",
        "        K_avgs += [data['K_avg']]\n",
        "        K_nngps += [data['K_nngp']]\n",
        "        avg_counts += [data['avg_count']]\n",
        "        nTs += [data['nT']]\n",
        "        beta = data['beta']\n",
        "\n",
        "## Preprocess NT kernels\n",
        "for i, K_width in zip(np.arange(len(K_avgs)), K_avgs):\n",
        "    for j, K in enumerate(K_width):\n",
        "        K_avgs[i][j] =  convert_nt(K)/avg_count"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dUcuMYDgOAg"
      },
      "source": [
        "depths = np.arange(len(K_avgs[0]))\n",
        "deviation = []\n",
        "deviation_th = []\n",
        "\n",
        "for K_exp, K_nngp, K_theory, hidden_width in zip(K_avgs, K_nngps, K_theories, hidden_widths):\n",
        "    dev_width = []\n",
        "    dev_width_th = []\n",
        "    for j, K, K_nn, K_th in zip(np.arange(len(K_exp)), K_exp, K_nngp, [*K_theory,0,0]):        \n",
        "        if len(K.shape) == 6:\n",
        "            K = K.reshape(N_tr, N_tr, resized**2, resized**2)\n",
        "            K_nn = K_nn.reshape(N_tr, N_tr, resized**2, resized**2)\n",
        "            K_th = K_th.reshape(N_tr, N_tr, resized**2, resized**2)\n",
        "        dev_width += [np.linalg.norm(K - K_nn)]\n",
        "        dev_width_th += [np.linalg.norm(K_th - K_nn)]\n",
        "        \n",
        "        \n",
        "    deviation += [dev_width]\n",
        "    deviation_th += [dev_width_th]\n",
        "\n",
        "deviation = np.array(deviation)\n",
        "deviation_th = np.array(deviation_th)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzGkCAPieEYi"
      },
      "source": [
        "widths = [width[0] for width in hidden_widths]\n",
        "deviation = np.array(deviation)\n",
        "plt.figure(figsize=(6,5))\n",
        "print(deviation.shape)\n",
        "for l in range(2):\n",
        "    plt.loglog(widths, deviation[:,l], 'o', label='layer %d'%(l+1), color = 'C%d'%l)\n",
        "\n",
        "\n",
        "deviation_th = np.array(deviation_th)\n",
        "for l in range(2):\n",
        "    if l == 0:\n",
        "        plt.loglog(widths, deviation_th[:,l],'--', color = 'C%d'%l)\n",
        "    else:\n",
        "        plt.loglog(widths, deviation_th[:,l],'--', color = 'C%d'%l)\n",
        "        \n",
        "plt.xlabel(r'Width', fontsize=20)\n",
        "plt.ylabel(r'$||K_{exp} - K_{GP}||_F$', fontsize=20)\n",
        "plt.gca().tick_params(axis='both', which = 'major', labelsize=14)\n",
        "plt.gca().tick_params(axis='both', which = 'minor', labelsize=12)\n",
        "plt.legend(fontsize=16)  \n",
        "plt.tight_layout()\n",
        "plt.savefig('one_over_width_%s_sgld.png'%model_type, dpi=600)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThN56npvgWnG"
      },
      "source": [
        "lay_idx = 1\n",
        "img_idx1 = 14\n",
        "img_idx2 = img_idx1\n",
        "\n",
        "for i in range(len(K_avgs)):\n",
        "    K_exp = [np.moveaxis(K, 3, 4).reshape(N_tr,N_tr,resized**2,resized**2) for K in K_avgs[0][:-2]]\n",
        "    K_nngp_th = [np.moveaxis(K, 3, 4).reshape(N_tr,N_tr,resized**2,resized**2) for K in K_nngp[:-2]]\n",
        "    K_th = [np.moveaxis(K, 3, 4).reshape(N_tr,N_tr,resized**2,resized**2) for K in K_theories[0]]\n",
        "    \n",
        "    vmin = np.min(K_exp[lay_idx][img_idx1,img_idx2])\n",
        "    vmax = np.max(K_exp[lay_idx][img_idx1,img_idx2])\n",
        "    \n",
        "    print(np.abs(K_exp[lay_idx][img_idx1,img_idx2]/K_nngp_th[lay_idx][img_idx1,img_idx2]).mean())\n",
        "    print(np.abs(K_th[lay_idx][img_idx1,img_idx2]/K_nngp_th[lay_idx][img_idx1,img_idx2]).mean())\n",
        "\n",
        "    fig, axs = plt.subplots(1,3)\n",
        "    fig.subplots_adjust(wspace=-0)\n",
        "    fig.subplots_adjust(hspace=-0)\n",
        "    \n",
        "    axs[0].imshow(K_exp[lay_idx][img_idx1,img_idx2], cmap='RdBu_r', vmin=vmin, vmax=vmax)\n",
        "    axs[1].imshow(K_nngp_th[lay_idx][img_idx1,img_idx2], cmap='RdBu_r', vmin=vmin, vmax=vmax)\n",
        "    im = axs[2].imshow((K_exp[lay_idx][img_idx1,img_idx2]-K_nngp_th[lay_idx][img_idx1,img_idx2])*10, cmap='RdBu_r', vmin=vmin, vmax=vmax)\n",
        "    cbar_ax = fig.add_axes([0.93, 0.32, 0.02, 0.35])\n",
        "    fig.colorbar(im, cax=cbar_ax)\n",
        "    \n",
        "    plt.setp(axs[0].get_xticklabels(), visible=False)\n",
        "    plt.setp(axs[0].get_yticklabels(), visible=False)\n",
        "    plt.setp(axs[1].get_xticklabels(), visible=False)\n",
        "    plt.setp(axs[1].get_yticklabels(), visible=False)\n",
        "    plt.setp(axs[2].get_xticklabels(), visible=False)\n",
        "    plt.setp(axs[2].get_yticklabels(), visible=False)\n",
        "    axs[0].tick_params(axis='both', which='both', length=0)\n",
        "    axs[1].tick_params(axis='both', which='both', length=0)\n",
        "    axs[2].tick_params(axis='both', which='both', length=0)\n",
        "    \n",
        "    \n",
        "    axs[0].set_title('$K_{exp}^{(%d)}$'%(lay_idx+1))\n",
        "    axs[1].set_title('$K_{GP}^{(%d)}$'%(lay_idx+1))\n",
        "    axs[2].set_title('$K_{exp}^{(%d)} - K_{GP}^{(%d)}$'%(lay_idx+1,lay_idx+1))\n",
        "    \n",
        "    plt.savefig('kernel_conv_at_layer_%d.png'%(lay_idx+1), dpi=600, bbox_inches='tight', pad_inches=0)\n",
        "    plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vtgJMINgaVA"
      },
      "source": [
        "data_limit = 4000\n",
        "\n",
        "lay_idx = 0\n",
        "xs = []\n",
        "plt.figure(figsize=(6,6))\n",
        "for width_idx in [0, 2, -1]:\n",
        "    K_exp = [K.reshape(N_tr,N_tr,resized**2,resized**2) for K in K_avgs[width_idx][:2]]\n",
        "    K_nngp_th = [K.reshape(N_tr,N_tr,resized**2,resized**2) for K in K_nngp[:2]]\n",
        "    K_th = [K.reshape(N_tr,N_tr,resized**2,resized**2) for K in K_theories[width_idx]]\n",
        "    \n",
        "    x = (K_exp[lay_idx]-K_nngp_th[lay_idx]).reshape(-1)[:data_limit]\n",
        "    y = (K_th[lay_idx]-K_nngp_th[lay_idx]).reshape(-1)[:data_limit]\n",
        "    \n",
        "    if width_idx == 0:\n",
        "        plt.plot(np.linspace(min(x), max(x),1000), np.linspace(min(x), max(x),1000),'k--')\n",
        "    \n",
        "    print(np.mean(K_exp[lay_idx]/K_th[lay_idx]), np.abs(x/y).mean())\n",
        "    plt.scatter(x,y, label='width = %d'%widths[width_idx])\n",
        "\n",
        "plt.xticks(fontsize=14)\n",
        "plt.yticks(fontsize=14)\n",
        "plt.legend(fontsize=16, loc='upper left')  \n",
        "plt.ticklabel_format(style='sci', axis='x', scilimits=(0,0))\n",
        "plt.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
        "plt.xlabel('$K_{exp}^{(%d)} - K_{GP}^{(%d)}$'%(lay_idx + 1,lay_idx + 1), fontsize=20)\n",
        "plt.ylabel('$K_{th}^{(%d)} - K_{GP}^{(%d)}$'%(lay_idx + 1,lay_idx + 1), fontsize=20)\n",
        "plt.tight_layout()\n",
        "plt.savefig('k-nngp_cov_cnn_layer_%d.png'%(lay_idx+1), dpi=600)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SCJzTI9grdb"
      },
      "source": [
        "## MNIST Digits"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zILFPvRHggZ2"
      },
      "source": [
        "Gxx_fcn = x_train.reshape(N_tr,-1) @ x_train.reshape(N_tr,-1).T / x_train.reshape(N_tr,-1).shape[1]\n",
        "Gxx = np.moveaxis(np.tensordot(x_train, x_train, (3, 3)), (3,2), (1,4)) ## Tensordot in channel axis\n",
        "Gyy = y_train @ y_train.T / y_train.shape[1]\n",
        "\n",
        "idx = 12\n",
        "\n",
        "plt.imshow(x_train[idx].squeeze())\n",
        "plt.gca().get_xaxis().set_visible(False)\n",
        "plt.gca().get_yaxis().set_visible(False)\n",
        "plt.title('$Digit: 2$', fontsize=22)\n",
        "plt.savefig('single_mnist_image.png', dpi=600)\n",
        "plt.show()\n",
        "\n",
        "plt.imshow(Gxx_fcn)\n",
        "plt.gca().get_xaxis().set_visible(False)\n",
        "plt.gca().get_yaxis().set_visible(False)\n",
        "plt.title('$G_{xx}$', fontsize=22)\n",
        "plt.savefig('gxx_fcn.png', dpi=600)\n",
        "plt.show()\n",
        "\n",
        "plt.imshow(Gxx[idx,idx].reshape(resized**2,resized**2))\n",
        "plt.gca().get_xaxis().set_visible(False)\n",
        "plt.gca().get_yaxis().set_visible(False)\n",
        "plt.title('$G_{xx}$ (Tensor)', fontsize=22)\n",
        "plt.savefig('gxx_cnn.png', dpi=600)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.imshow(Gyy)\n",
        "plt.gca().get_xaxis().set_visible(False)\n",
        "plt.gca().get_yaxis().set_visible(False)\n",
        "plt.title('$G_{yy}$', fontsize=22)\n",
        "plt.savefig('gyy_fcn.png', dpi=600)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIBP6kWUKeTt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}